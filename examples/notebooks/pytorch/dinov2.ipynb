{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "This example requires the following dependencies to be installed:\n",
        "pip install lightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1",
      "metadata": {
        "collapsed": true,
        "id": "1",
        "outputId": "728d833a-8360-46b9-8a47-ff0930e8ec02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightly\n",
            "  Downloading lightly-1.5.22-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from lightly) (2025.8.3)\n",
            "Collecting hydra-core>=1.0.0 (from lightly)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.12/dist-packages (from lightly) (2.0.2)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from lightly) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from lightly) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from lightly) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.12/dist-packages (from lightly) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from lightly) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from lightly) (0.23.0+cu126)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.12/dist-packages (from lightly) (2.11.7)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly)\n",
            "  Downloading pytorch_lightning-2.5.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.12/dist-packages (from lightly) (2.5.0)\n",
            "Collecting aenum>=3.1.11 (from lightly)\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.0.0->lightly) (25.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from lightly_utils~=0.0.0->lightly) (11.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.5->lightly) (0.4.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch_lightning>=1.0.4->lightly) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch_lightning>=1.0.4->lightly)\n",
            "  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning>=1.0.4->lightly)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->lightly) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.0->lightly) (3.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->lightly) (3.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.12.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->lightly) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.20.1)\n",
            "Downloading lightly-1.5.22-py3-none-any.whl (859 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.3/859.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading pytorch_lightning-2.5.3-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.2/828.2 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.1-py3-none-any.whl (982 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aenum, lightning-utilities, lightly_utils, hydra-core, torchmetrics, pytorch_lightning, lightly\n",
            "Successfully installed aenum-3.1.16 hydra-core-1.3.2 lightly-1.5.22 lightly_utils-0.0.2 lightning-utilities-0.15.2 pytorch_lightning-2.5.3 torchmetrics-1.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lightly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "Note: The model and training settings do not follow the reference settings\n",
        "from the paper. The settings are chosen such that the example can easily be\n",
        "run on a small dataset with a single GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from timm.models.vision_transformer import vit_small_patch16_224\n",
        "from torch import Tensor\n",
        "from torch.nn import Module\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "outputs": [],
      "source": [
        "from lightly.loss import DINOLoss, IBOTPatchLoss, KoLeoLoss\n",
        "from lightly.models.modules import DINOv2ProjectionHead, MaskedVisionTransformerTIMM\n",
        "from lightly.models.utils import (\n",
        "    random_block_mask,\n",
        "    update_drop_path_rate,\n",
        "    update_momentum,\n",
        ")\n",
        "from lightly.transforms.dino_transform import DINOTransform\n",
        "from lightly.utils.scheduler import cosine_schedule, linear_warmup_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "def freeze_eval_module(module: Module) -> None:\n",
        "    \"\"\"Freeze the parameters of a module.\"\"\"\n",
        "    for param in module.parameters():\n",
        "        param.requires_grad = False\n",
        "    module.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "outputs": [],
      "source": [
        "class DINOv2Head(Module):\n",
        "    def __init__(\n",
        "        self, dino_head: DINOv2ProjectionHead, ibot_head: DINOv2ProjectionHead\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.dino_head = dino_head\n",
        "        self.ibot_head = ibot_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8",
      "metadata": {
        "id": "8"
      },
      "outputs": [],
      "source": [
        "class DINOv2(Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        ibot_separate_head: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Backbones\n",
        "        vit_teacher = vit_small_patch16_224(\n",
        "            pos_embed=\"learn\",\n",
        "            dynamic_img_size=True,\n",
        "            init_values=1e-5,\n",
        "        )\n",
        "        self.teacher_backbone = MaskedVisionTransformerTIMM(\n",
        "            vit=vit_teacher,\n",
        "            antialias=False,\n",
        "            pos_embed_initialization=\"skip\",\n",
        "        )\n",
        "        self.student_backbone = copy.deepcopy(self.teacher_backbone)\n",
        "        update_drop_path_rate(\n",
        "            self.student_backbone.vit,\n",
        "            drop_path_rate=0.1,  # we recommend using smaller rates like 0.1 for vit-s-14\n",
        "            mode=\"uniform\",\n",
        "        )\n",
        "\n",
        "        freeze_eval_module(self.teacher_backbone)\n",
        "\n",
        "        # Heads\n",
        "        dino_head = partial(\n",
        "            DINOv2ProjectionHead,\n",
        "            input_dim=384,\n",
        "        )\n",
        "\n",
        "        teacher_dino_head = dino_head()\n",
        "        student_dino_head = dino_head()\n",
        "\n",
        "        ibot_head = partial(\n",
        "            DINOv2ProjectionHead,\n",
        "            input_dim=384,\n",
        "        )\n",
        "\n",
        "        if ibot_separate_head:\n",
        "            teacher_ibot_head = ibot_head()\n",
        "            student_ibot_head = ibot_head()\n",
        "        else:\n",
        "            teacher_ibot_head = teacher_dino_head\n",
        "            student_ibot_head = student_dino_head\n",
        "\n",
        "        self.teacher_head = DINOv2Head(\n",
        "            dino_head=teacher_dino_head,\n",
        "            ibot_head=teacher_ibot_head,\n",
        "        )\n",
        "        self.student_head = DINOv2Head(\n",
        "            dino_head=student_dino_head,\n",
        "            ibot_head=student_ibot_head,\n",
        "        )\n",
        "\n",
        "        freeze_eval_module(self.teacher_head)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.teacher_backbone(x)\n",
        "\n",
        "    def forward_teacher(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
        "        features = self.teacher_backbone.encode(x)\n",
        "        cls_tokens = features[:, 0]\n",
        "        return cls_tokens, features\n",
        "\n",
        "    def forward_student(\n",
        "        self, x: Tensor, mask: Tensor | None\n",
        "    ) -> tuple[Tensor, Tensor | None]:\n",
        "        features = self.student_backbone.encode(x, mask=mask)\n",
        "        cls_tokens = features[:, 0]\n",
        "        masked_features = None if mask is None else features[mask]\n",
        "        return cls_tokens, masked_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9",
      "metadata": {
        "id": "9",
        "outputId": "061ee936-3242-440c-f7ae-b4b755a255f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        }
      ],
      "source": [
        "model = DINOv2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "outputs": [],
      "source": [
        "transform = DINOTransform(\n",
        "    global_crop_scale=(0.32, 1),\n",
        "    local_crop_scale=(0.05, 0.32),\n",
        "    n_local_views=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "outputs": [],
      "source": [
        "# We ignore object detection annotations by setting target_transform to return 0.\n",
        "def target_transform(t):\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "12",
      "metadata": {
        "collapsed": true,
        "id": "12",
        "outputId": "f1932076-0169-4281-e535-54c4a17305a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DINOv2(\n",
              "  (teacher_backbone): MaskedVisionTransformerTIMM(\n",
              "    (vit): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Linear(in_features=384, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (student_backbone): MaskedVisionTransformerTIMM(\n",
              "    (vit): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): DropPath(drop_prob=0.100)\n",
              "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): DropPath(drop_prob=0.100)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Linear(in_features=384, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (teacher_head): DINOv2Head(\n",
              "    (dino_head): DINOv2ProjectionHead(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=384, out_features=2048, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=2048, out_features=256, bias=True)\n",
              "      )\n",
              "      (last_layer): Linear(in_features=256, out_features=65536, bias=False)\n",
              "    )\n",
              "    (ibot_head): DINOv2ProjectionHead(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=384, out_features=2048, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=2048, out_features=256, bias=True)\n",
              "      )\n",
              "      (last_layer): Linear(in_features=256, out_features=65536, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (student_head): DINOv2Head(\n",
              "    (dino_head): DINOv2ProjectionHead(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=384, out_features=2048, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=2048, out_features=256, bias=True)\n",
              "      )\n",
              "      (last_layer): Linear(in_features=256, out_features=65536, bias=False)\n",
              "    )\n",
              "    (ibot_head): DINOv2ProjectionHead(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=384, out_features=2048, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=2048, out_features=256, bias=True)\n",
              "      )\n",
              "      (last_layer): Linear(in_features=256, out_features=65536, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/datasets/CVC"
      ],
      "metadata": {
        "id": "uglONSOZlTe-",
        "outputId": "6e8e3539-d3a8-4237-c209-a69c29435dd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uglONSOZlTe-",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets/CVC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf .ipynb_checkpoints\n",
        "!ls -a"
      ],
      "metadata": {
        "id": "EsWucCeElXwy",
        "outputId": "13c18f76-7c0b-4409-c14a-7646d84369a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EsWucCeElXwy",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  2.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "13",
      "metadata": {
        "collapsed": true,
        "id": "13"
      },
      "outputs": [],
      "source": [
        "# dataset = torchvision.datasets.VOCDetection(\n",
        "#     \"datasets/pascal_voc\",\n",
        "#     download=True,\n",
        "#     transform=transform,\n",
        "#     target_transform=target_transform,\n",
        "# )\n",
        "# Or create a dataset from a folder containing images or videos.\n",
        "import lightly.data as data\n",
        "dataset = data.LightlyDataset(\"/content/datasets\",transform=transform,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "14",
      "metadata": {
        "id": "14"
      },
      "outputs": [],
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "15",
      "metadata": {
        "id": "15"
      },
      "outputs": [],
      "source": [
        "# Create the loss functions.\n",
        "dino_criterion = DINOLoss()\n",
        "ibot_criterion = IBOTPatchLoss()\n",
        "koleo_criterion = KoLeoLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "16",
      "metadata": {
        "id": "16"
      },
      "outputs": [],
      "source": [
        "# Move loss to correct device because it also contains parameters.\n",
        "dino_criterion = dino_criterion.to(device)\n",
        "ibot_criterion = ibot_criterion.to(device)\n",
        "koleo_criterion = koleo_criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "17",
      "metadata": {
        "id": "17"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "18",
      "metadata": {
        "id": "18"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "num_batches = len(dataloader)\n",
        "total_steps = epochs * num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19",
      "metadata": {
        "id": "19"
      },
      "outputs": [],
      "source": [
        "print(\"Starting Training\")\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        views = batch[0]\n",
        "        views = [view.to(device) for view in views]\n",
        "        global_views = torch.cat(views[:2])\n",
        "        local_views = torch.cat(views[2:])\n",
        "\n",
        "        # Masking\n",
        "        B = len(global_views)\n",
        "        sequence_length = model.teacher_backbone.sequence_length\n",
        "        mask = global_views.new_zeros((B, sequence_length), dtype=torch.bool)\n",
        "\n",
        "        # Mask patches except class token.\n",
        "        H, W = model.teacher_backbone.vit.patch_embed.grid_size\n",
        "        assert (\n",
        "            H * W == sequence_length - 1\n",
        "        ), f\"Unexpected grid size: {H}x{W}, sequence_length {sequence_length}\"\n",
        "        block_mask = random_block_mask(size=(B, H, W), device=mask.device)\n",
        "        mask[:, 1:] = block_mask.flatten(start_dim=1)\n",
        "\n",
        "        # Teacher forward\n",
        "        with torch.no_grad():\n",
        "            teacher_cls_token, teacher_features = model.forward_teacher(global_views)\n",
        "            teacher_cls_out = model.teacher_head.dino_head.forward(teacher_cls_token)\n",
        "            teacher_masked_out = model.teacher_head.ibot_head.forward(\n",
        "                teacher_features[mask]\n",
        "            )\n",
        "\n",
        "        # Student forward\n",
        "        (\n",
        "            student_global_cls_token,\n",
        "            student_global_masked_features,\n",
        "        ) = model.forward_student(global_views, mask=mask)\n",
        "        student_global_cls_out = model.student_head.dino_head.forward(\n",
        "            student_global_cls_token\n",
        "        )\n",
        "        student_global_masked_out = model.student_head.ibot_head.forward(\n",
        "            student_global_masked_features\n",
        "        )\n",
        "        student_local_cls_token, _ = model.forward_student(local_views, mask=None)\n",
        "        student_local_cls_out = model.student_head.dino_head.forward(\n",
        "            student_local_cls_token\n",
        "        )\n",
        "        student_cls_out = torch.cat([student_global_cls_out, student_local_cls_out])\n",
        "\n",
        "        # Calculate current global step based on epoch and batch index.\n",
        "        global_step = epoch * num_batches + batch_idx\n",
        "\n",
        "        # Calculate the loss.\n",
        "        teacher_temp = linear_warmup_schedule(\n",
        "            step=global_step,\n",
        "            warmup_steps=int(30 / epochs * total_steps),\n",
        "            start_value=0.04,\n",
        "            end_value=0.07,\n",
        "        )\n",
        "        dino_loss = dino_criterion(\n",
        "            teacher_out=teacher_cls_out.chunk(2),\n",
        "            student_out=student_cls_out.chunk(len(views)),\n",
        "            teacher_temp=teacher_temp,\n",
        "        )\n",
        "        ibot_loss = ibot_criterion(\n",
        "            teacher_out=teacher_masked_out,\n",
        "            student_out=student_global_masked_out,\n",
        "            mask=block_mask,\n",
        "            teacher_temp=teacher_temp,\n",
        "        )\n",
        "        koleo_loss = 0.1 * sum(\n",
        "            koleo_criterion(t) for t in student_global_cls_token.chunk(2)\n",
        "        )\n",
        "        loss = dino_loss + ibot_loss + koleo_loss\n",
        "\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "\n",
        "        # Optionally zero out the learning rate of the last layer.\n",
        "        if epoch < 1:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                if \"last_layer\" in param_group:\n",
        "                    param_group[\"lr\"] = 0.0\n",
        "\n",
        "        # Apply weight decay schedule.\n",
        "        weight_decay = cosine_schedule(\n",
        "            step=global_step,\n",
        "            max_steps=total_steps,\n",
        "            start_value=0.04,\n",
        "            end_value=0.4,\n",
        "        )\n",
        "\n",
        "        # Update weight decay directly for all parameter groups.\n",
        "        for group in optimizer.param_groups:\n",
        "            if group[\"weight_decay\"] != 0.0:\n",
        "                group[\"weight_decay\"] = weight_decay\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Momentum update teacher.\n",
        "        momentum = cosine_schedule(\n",
        "            step=global_step,\n",
        "            max_steps=total_steps,\n",
        "            start_value=0.992,\n",
        "            end_value=1.0,\n",
        "        )\n",
        "        update_momentum(model.student_backbone, model.teacher_backbone, m=momentum)\n",
        "        update_momentum(model.student_head, model.teacher_head, m=momentum)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}